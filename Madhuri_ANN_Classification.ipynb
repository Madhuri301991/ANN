{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ANN"
      ],
      "metadata": {
        "id": "jaU1tqS3Uge9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the libraries"
      ],
      "metadata": {
        "id": "BswVY0qtUjef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "a9oG57iXUnYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vWqCBi2GVD8A",
        "outputId": "66cb59d5-a7b4-4d5a-fe00-4e55fac63a25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Data Preprocessing"
      ],
      "metadata": {
        "id": "QG3NKXqMWCzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the dataset"
      ],
      "metadata": {
        "id": "HYDw_gdRWHKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=pd.read_csv('Churn_Modelling.csv')\n",
        "X=dataset.iloc[:,3:-1].values\n",
        "y=dataset.iloc[:,-1].values\n"
      ],
      "metadata": {
        "id": "7cDv5MOtWKK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "sZsMvAU1axee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cff3052-1eef-44c5-9e24-8b66d1e719db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 'Female' ... 1 1 101348.88]\n",
            " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
            " [502 'France' 'Female' ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 'Female' ... 0 1 42085.58]\n",
            " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
            " [792 'France' 'Female' ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06fmr5MAaxzm",
        "outputId": "e49dbfeb-96d9-4b4f-b891-bf8667c1b57c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 ... 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding Categorical data"
      ],
      "metadata": {
        "id": "89B6kURkbMT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label encoding the gender column"
      ],
      "metadata": {
        "id": "Z8gmxURobQMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from  sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "X[:,2]=le.fit_transform(X[:,2])   #X[:,2] will take all rows of index 2nd column"
      ],
      "metadata": {
        "id": "NufeeyRgcLbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "2jfQr7S6dfsw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53db5359-bcef-45ac-9b56-cfc539391494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 0 ... 1 1 101348.88]\n",
            " [608 'Spain' 0 ... 0 1 112542.58]\n",
            " [502 'France' 0 ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 0 ... 0 1 42085.58]\n",
            " [772 'Germany' 1 ... 1 0 92888.52]\n",
            " [792 'France' 0 ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One Hot encoding the 'Geography' column"
      ],
      "metadata": {
        "id": "IQgqECgldrEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct=ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder='passthrough')\n",
        "X=np.array(ct.fit_transform(X))"
      ],
      "metadata": {
        "id": "LcYkZsOGflTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "cpAEJ2x3gsG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b95fab5-e5ec-4d02-d50c-c38eb1de9e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
            " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
            " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
            " ...\n",
            " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
            " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
            " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the dataset into training set and test set"
      ],
      "metadata": {
        "id": "44VFgPDEhXgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "-z8ofZSFhcWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Scaling"
      ],
      "metadata": {
        "id": "sAvdyzOhlfrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#feature scaling is absolutely compulsory for deep learning \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.transform(X_test)\n"
      ],
      "metadata": {
        "id": "Skb6VMrpli2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 2: Building the ANN"
      ],
      "metadata": {
        "id": "FUqN8Ln5hL9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps\n",
        "\n",
        "*   Intialize the ANN as a sequence of layers\n",
        "*   add the input layer and the first hidden layer composed of neurons\n",
        "*   add the second hidden layer to build a deep learning model\n",
        "*   add the output layer which will contain what we want to predict\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "su8P2YSoopaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the ANN"
      ],
      "metadata": {
        "id": "yEG3TJ6Bpe_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann=tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "la_RGguapiM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding the input layer and the first hidden layer"
      ],
      "metadata": {
        "id": "MdnliwDvdwwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fully connected layer will be created as an object of dense class\n",
        "#units correspond to number of neurons we want to have in first hidden layer \n",
        "#input neurons will be features ie column name --> creditscore, gender,georgaphy...upto Estimated salary\n",
        "#first input layer is created with some hidden neuron\n",
        "# experiement with different no of neurons ( this is called hyperparameter) take units=6\n",
        "#activation function of the hidden layers for fully connected layer will be rectifier function\n",
        "ann.add(tf.keras.layers.Dense(units=6,activation='relu'))\n",
        "#creates a first fully working connected hidden layer \n"
      ],
      "metadata": {
        "id": "KOz03cx6eGHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding the second hidden layer"
      ],
      "metadata": {
        "id": "Neq_y9lpg8Kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6,activation='relu'))"
      ],
      "metadata": {
        "id": "szMLAvvPhDJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding the output layer"
      ],
      "metadata": {
        "id": "l7ZXF9W9hN0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))\n",
        "#units=1 because we want the output neuron to have binary prediction 0 or 1 (leaves or stays in bank)\n",
        "#sigmoid activation function in the output layer gives the binary probabilty of the outcome\n",
        "#sigmoid gives probability of each customer whether it leaves the bank"
      ],
      "metadata": {
        "id": "1Z6bvXNBhd-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the ANN"
      ],
      "metadata": {
        "id": "P30JEKEsi2Hg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Compiling the ANN using optimizer, loss function and metrics\n",
        "*   Training the ANN on the training set over a certain number of epochs:\n",
        "\n"
      ],
      "metadata": {
        "id": "1mpcspFaNqaJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the ANN"
      ],
      "metadata": {
        "id": "VzFtf8g1N6qU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   good optimizer confirms to stochastic gradient descend. stochastic gradient: update the weights to reduce the loss between the predicted and real results, during training, at each iteration, we compare the prediction in the batch to the real results in the same batch, so stochastic gradient updates the weight\n",
        "*   adam optimizer is the stochastic gradient descent, so next iteration, reduce the loss\n",
        "*   loss - weight computed difference between the computed and real results\n",
        "*  accuracy is the evaluation metric of our model. metrics that evaluate the ANN training \n",
        "*   classification when you have to predict binary outcome -->1]loss function is always 'binary_crossentropy'\n",
        "*   for nonbinary classification predicting three different categories -->#1]loss function is 'categorical_crossentropy'  #2]activation must be sigmoid not softmax\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HaJ8CtRPQz4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DwrzHWIYOCXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the ANN"
      ],
      "metadata": {
        "id": "7AHxKrfiN-IY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#batch training compares several real results to several predicted results in the batch.\n",
        "#batch default size=32\n",
        "#epoch is used to improve the accuracy over time \n",
        "ann.fit(X_train,y_train,batch_size=32,epochs=100)\n",
        "#accuracy is averging around 0.86"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wddt8V-4SHgT",
        "outputId": "bc0a28a3-4cc5-4809-c362-8686fc1bbc78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6606 - accuracy: 0.6181\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4972 - accuracy: 0.7951\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7991\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4390 - accuracy: 0.8056\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8091\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8138\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8196\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8250\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8299\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8345\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8390\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8441\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8470\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8515\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8531\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8560\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8569\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8586\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3443 - accuracy: 0.8602\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8610\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3421 - accuracy: 0.8606\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.8610\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.8600\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8608\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.8590\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8609\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3382 - accuracy: 0.8616\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8626\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8609\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 0.8620\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8625\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3366 - accuracy: 0.8621\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8637\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8627\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8640\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8616\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8626\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3349 - accuracy: 0.8637\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8629\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8619\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8625\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8627\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8648\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8625\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8629\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8626\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8636\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3334 - accuracy: 0.8625\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8648\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8637\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8643\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8633\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8646\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8655\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8619\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8633\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8627\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8622\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8631\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8640\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8635\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8633\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8630\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3319 - accuracy: 0.8614\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3316 - accuracy: 0.8629\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3319 - accuracy: 0.8649\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3318 - accuracy: 0.8649\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8637\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8621\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8648\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8630\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8631\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8620\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8606\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8633\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8625\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3311 - accuracy: 0.8619\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3312 - accuracy: 0.8630\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3309 - accuracy: 0.8631\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8633\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8610\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3309 - accuracy: 0.8636\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3313 - accuracy: 0.8625\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3307 - accuracy: 0.8627\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8635\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3307 - accuracy: 0.8633\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8633\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3307 - accuracy: 0.8618\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8643\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3308 - accuracy: 0.8654\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8630\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8622\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8641\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8637\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8639\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8635\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8624\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8631\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8643\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8630\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdbe5360590>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Making the predications and evaluating the result"
      ],
      "metadata": {
        "id": "IPXMQ3byTakx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use our ANN model to predict if the customer with the following information will leave the bank\n",
        "\n",
        "*   Geography : Finance\n",
        "*   Credit Score : 600 \n",
        "*   Gender : Male\n",
        "*   Age : 40 years old \n",
        "*   Tenure : 3 years\n",
        "*   Balance : $60000\n",
        "*   Number of products : 2\n",
        "\n",
        "\n",
        "*    Does this customer have a credit card ? Yes\n",
        "*   Is this customer an Active Member : Yes\n",
        "\n",
        "\n",
        "*   Estimated Salary : $50000\n",
        "*   So, should we say goodbye to that customer?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fu6nIQSwooPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#enter the information we want to predict\n",
        "print(ann.predict(sc.transform([[1,0,0,600,1,40,3,60000,2,1,1,50000]]))>0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q178O9nwqjrd",
        "outputId": "424f9785-1e63-40b2-e5d6-4fbd4303b074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   use the predict method to know that the customer with the following information will leave the bank.  \n",
        "*    input to predict method will be 2D array double pair of square brackets. OneHotEncoder applied to geogrphy column leads to dummy vairable of FRANCE 1 0 0. Dummy variables are always created in the first column\n",
        "\n",
        "*   predict method should be only applied to the type of observation on which training was done, scaling needs to be applied on the observation\n",
        "*   sc object is used to perform scaled transformation on the entered dataset\n",
        "*   transform method can be only applied on test set \n",
        "\n",
        "\n",
        "*  True -- customer leaves bank\n",
        "*  False -- customer wont leave the bank\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eXBjTJiIuuU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting the test set results"
      ],
      "metadata": {
        "id": "XHirLG85z3Di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#display next to each other -- vector of prediction and vector of real results\n",
        "#ann returns results in the form of probabilites\n",
        "y_pred=ann.predict(X_test)\n",
        "y_pred=(y_pred>0.5) \n",
        "#if y_pred between 0.5 and 1 value will be 1, because it is true\n",
        "#if y_pred between 0 and 0.5 value will be 0\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1))\n",
        "#displays predications results and real results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-pubh7p0IHX",
        "outputId": "57e083d1-0ab7-4f21-ee26-5cf059f4bf74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making the confusion matrix"
      ],
      "metadata": {
        "id": "pTkE5Nft3Qpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "cm=confusion_matrix(y_test,y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test,y_pred)\n",
        "# received accuracy of 85 percent = 0.8585"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrFmMI6F3TWX",
        "outputId": "9820b0cc-bd99-4dfc-8e83-92f402e8bfc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1517   78]\n",
            " [ 205  200]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8585"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}